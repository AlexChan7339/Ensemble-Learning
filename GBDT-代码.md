# GBDT-ä»£ç 

## sklearnä»£ç 

*class* `sklearn.ensemble.GradientBoostingClassifier`(*, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)

*class* `sklearn.ensemble.GradientBoostingRegressor`(*, loss='squared_error', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)

### å‚æ•°è§£è¯»

| ç±»å‹               | å‚æ•°/å±æ€§                                                    |
| ------------------ | ------------------------------------------------------------ |
| **è¿­ä»£è¿‡ç¨‹**       | **å‚æ•°ï¼š**<br>&emsp;n_estimatorsï¼šé›†æˆç®—æ³•ä¸­å¼±è¯„ä¼°å™¨æ•°é‡ï¼Œå¯¹Boostingç®—æ³•è€Œè¨€ä¸ºå®é™…è¿­ä»£æ¬¡æ•°<br><br>&emsp;learning_rateï¼šBoostingç®—æ³•ä¸­çš„å­¦ä¹ ç‡ï¼Œå½±å“å¼±è¯„ä¼°å™¨ç»“æœçš„åŠ æƒæ±‚å’Œè¿‡ç¨‹<br><br>&emsp;loss, alphaï¼šéœ€è¦ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ï¼Œä»¥åŠç‰¹å®šæŸå¤±å‡½æ•°éœ€è¦è°ƒèŠ‚çš„é˜ˆå€¼<br><br>&emsp;initï¼šåˆå§‹åŒ–é¢„æµ‹ç»“æœ$H_0$çš„è®¾ç½®<br><br>**å±æ€§ï¼š**<br><br>   loss_ ï¼šè¿”å›å…·ä½“çš„æŸå¤±å‡½æ•°å¯¹è±¡<br><br>&emsp;init_ï¼šè¿”å›å…·ä½“çš„åˆå§‹åŒ–è®¾ç½®<br><br>&emsp;estimators_ï¼šè¿”å›å®é™…å»ºç«‹çš„è¯„ä¼°å™¨åˆ—è¡¨<br><br>&emsp;n_estimators_ï¼šè¿”å›å®é™…è¿­ä»£æ¬¡æ•° |
| å¼±è¯„ä¼°å™¨ç»“æ„       | criterionï¼šå¼±è¯„ä¼°å™¨åˆ†ææ—¶çš„ä¸çº¯åº¦è¡¡é‡æŒ‡æ ‡<br/><br/>max_depthï¼šå¼±è¯„ä¼°å™¨è¢«å…è®¸çš„æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤3<br/><br/>min_samples_splitï¼šå¼±è¯„ä¼°å™¨åˆ†ææ—¶ï¼Œçˆ¶èŠ‚ç‚¹ä¸Šæœ€å°‘è¦æ‹¥æœ‰çš„æ ·æœ¬ä¸ªæ•°<br/><br/>min_samples_leafï¼šå¼±è¯„ä¼°å™¨çš„å¶å­èŠ‚ç‚¹ä¸Šæœ€å°‘è¦æ‹¥æœ‰çš„æ ·æœ¬ä¸ªæ•°<br/><br/>min_weight_fraction_leafï¼šå½“æ ·æœ¬æƒé‡è¢«è°ƒæ•´æ—¶ï¼Œå¶å­èŠ‚ç‚¹ä¸Šæœ€å°‘è¦æ‹¥æœ‰çš„æ ·æœ¬æƒé‡(    è®¾å®šäº†ä¸€ä¸ªå¶èŠ‚ç‚¹å¿…é¡»æ‹¥æœ‰çš„ç›¸å¯¹äºå…¨éƒ¨è®­ç»ƒæ ·æœ¬çš„æœ€å°æƒé‡å’Œçš„æ¯”ä¾‹ã€‚æƒé‡é€šå¸¸æ˜¯æ ·æœ¬æ•°é‡ï¼Œä½†åœ¨å¤„ç†åŠ æƒæ•°æ®æ—¶ï¼Œæƒé‡å¯èƒ½ä¸æ ·æœ¬æ•°é‡ä¸åŒã€‚ **æ§åˆ¶æ ‘çš„å¤æ‚åº¦**ï¼š)<br/><br/>max_leaf_nodesï¼šå¼±è¯„ä¼°å™¨ä¸Šæœ€å¤šå¯ä»¥æœ‰çš„å¶å­èŠ‚ç‚¹æ•°é‡<br/><br/>min_impurity_decreaseï¼šå¼±è¯„ä¼°å™¨åˆ†ææ—¶å…è®¸çš„æœ€å°ä¸çº¯åº¦ä¸‹é™é‡ |
| æå‰åœæ­¢           | å‚æ•°ï¼švalidation_fractionï¼šä»è®­ç»ƒé›†ä¸­æå–å‡ºã€ç”¨äºæå‰åœæ­¢çš„éªŒè¯æ•°æ®å æ¯”<br/><br/>n_iter_no_changeï¼šå½“éªŒè¯é›†ä¸Šçš„æŸå¤±å‡½æ•°å€¼è¿ç»­n_iter_no_changeæ¬¡æ²¡æœ‰ä¸‹é™<br/>æˆ–ä¸‹é™é‡ä¸è¾¾é˜ˆå€¼æ—¶ï¼Œåˆ™è§¦å‘æå‰åœæ­¢<br/><br/>tolï¼šæŸå¤±å‡½æ•°ä¸‹é™é‡çš„æœ€å°é˜ˆå€¼l<br>å±æ€§ï¼šn_estimators_ |
| å¼±è¯„ä¼°å™¨çš„è®­ç»ƒæ•°æ® | å‚æ•°ï¼š<br/><br/>&emsp;subsampleï¼šæ¯æ¬¡å»ºæ ‘ä¹‹å‰ï¼Œä»å…¨æ•°æ®é›†ä¸­è¿›è¡Œæœ‰æ”¾å›éšæœºæŠ½æ ·çš„æ¯”ä¾‹<br/><br/>&emsp;max_featuresï¼šæ¯æ¬¡å»ºæ ‘ä¹‹å‰ï¼Œä»å…¨ç‰¹å¾ä¸­éšæœºæŠ½æ ·ç‰¹å¾è¿›è¡Œåˆ†æçš„æ¯”ä¾‹<br/><br/>&emsp;random_stateï¼šéšæœºæ•°ç§å­ï¼Œæ§åˆ¶æ•´ä½“éšæœºæ¨¡å¼<br/><br/>å±æ€§ï¼š<br/><br/>&emsp;oob_improvementï¼šæ¯æ¬¡å»ºæ ‘ä¹‹åç›¸å¯¹äºä¸Šä¸€æ¬¡è¢‹å¤–åˆ†æ•°çš„å¢å‡<br/>&emsp;train_score_ï¼šæ¯æ¬¡å»ºæ ‘ä¹‹åç›¸å¯¹äºä¸Šä¸€æ¬¡éªŒè¯æ—¶è¢‹å†…åˆ†æ•°çš„å¢å‡ |
| å…¶ä»–               | ccp_alpha, warm_start                                        |

- è¿­ä»£è¿‡ç¨‹

  - n_estimatorsï¼šè¿­ä»£æ¬¡æ•°ï¼ˆå¼±è¯„ä¼°å™¨æ¬¡æ•°ï¼‰

    å¯¹äºæ ·æœ¬$x_i$ï¼Œé›†æˆç®—æ³•å½“ä¸­ä¸€å…±æœ‰ğ‘‡æ£µæ ‘ï¼Œåˆ™å‚æ•°`n_estimators`çš„å–å€¼ä¸ºT

  - learning_rate:å­¦ä¹ ç‡ï¼ˆæ§åˆ¶$(H(x_i))$çš„å¢é•¿é€Ÿåº¦

    $$H_t(x_i) = H_{t-1}(x_i) + \boldsymbol{\color{red}\eta} \phi_tf_t(x_i)$$

    æ³¨æ„ï¼š$\phi_t$ä¸ºç¬¬tæ£µæ ‘çš„æƒé‡

  - `init`ï¼šè¾“å…¥è®¡ç®—åˆå§‹é¢„æµ‹ç»“æœğ»0çš„ä¼°è®¡å™¨å¯¹è±¡ã€‚

    $$H_1(x_i) = H_{0}(x_i) + \phi_1f_1(x_i)$$ï¼šç”±äºæ²¡æœ‰ç¬¬0æ£µæ ‘çš„å­˜åœ¨ï¼Œå› æ­¤$H_0(x_i)$çš„å€¼åœ¨æ•°å­¦è¿‡ç¨‹åŠç®—æ³•å…·ä½“å®ç°è¿‡ç¨‹ä¸­éƒ½éœ€è¦è¿›è¡Œå•ç‹¬çš„ç¡®å®šï¼Œè¿™ä¸€ç¡®å®šè¿‡ç¨‹ç”±å‚æ•°`init`ç¡®å®šã€‚

    åœ¨è¯¥å‚æ•°ä¸­ï¼Œ**å¯ä»¥è¾“å…¥ä»»æ„è¯„ä¼°å™¨ã€å­—ç¬¦ä¸²"zero"ã€æˆ–è€…Noneå¯¹è±¡ï¼Œé»˜è®¤ä¸ºNoneå¯¹è±¡**ã€‚

    > **å½“è¾“å…¥ä»»æ„è¯„ä¼°å™¨æ—¶ï¼Œè¯„ä¼°å™¨å¿…é¡»è¦å…·å¤‡fitä»¥åŠpredict_probaåŠŸèƒ½(å› ä¸ºGBDTçš„åŸºå­¦ä¹ å™¨ä¸ºCARTï¼Œåˆ†ç±»å›å½’æ ‘)ï¼Œå³æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å†³ç­–æ ‘ã€é€»è¾‘å›å½’ç­‰å¯ä»¥è¾“å‡ºæ¦‚ç‡çš„æ¨¡å‹ã€‚å¦‚æœè¾“å‡ºä¸€ä¸ªå·²ç»è®­ç»ƒè¿‡ã€ä¸”ç²¾ç»†åŒ–è°ƒå‚åçš„æ¨¡å‹ï¼Œå°†ä¼šç»™GBDTæ ‘æ‰“ä¸‹åšå®çš„åŸºç¡€**ã€‚<br><br>
    > **å¡«å†™ä¸ºå­—ç¬¦ä¸²"zero"ï¼Œåˆ™ä»£è¡¨ä»¤$H_0 = 0$æ¥å¼€å§‹è¿­ä»£**ã€‚<br><br>
    > **ä¸å¡«å†™ï¼Œæˆ–å¡«å†™ä¸ºNoneå¯¹è±¡ï¼Œsklearnåˆ™ä¼šè‡ªåŠ¨é€‰æ‹©ç±»`DummyEstimator`ä¸­çš„æŸç§é»˜è®¤æ–¹å¼è¿›è¡Œé¢„æµ‹ä½œä¸º$H_0$çš„ç»“æœã€‚`DummyEstimator`ç±»æ˜¯sklearnä¸­è®¾ç½®çš„ä½¿ç”¨è¶…ç®€å•è§„åˆ™è¿›è¡Œé¢„æµ‹çš„ç±»ï¼Œå…¶ä¸­æœ€å¸¸è§çš„è§„åˆ™æ˜¯ç›´æ¥ä»è®­ç»ƒé›†æ ‡ç­¾ä¸­éšæœºæŠ½æ ·å‡ºç»“æœä½œä¸ºé¢„æµ‹æ ‡ç­¾ï¼Œä¹Ÿæœ‰é€‰æ‹©ä¼—æ•°ä½œä¸ºé¢„æµ‹æ ‡ç­¾ç­‰é€‰é¡¹**ã€‚

  - `init_`:å½“æ¨¡å‹è¢«æ‹Ÿåˆå®Œæ¯•ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¯¥å±æ€§æ¥è¿”å›è¾“å‡º$H_0$çš„è¯„ä¼°å™¨å¯¹è±¡

  - `n_estimators_`ï¼šå®é™…è¿­ä»£æ¬¡æ•°ï¼Œ`estimators_`ï¼šå®é™…å»ºç«‹çš„å¼±è¯„ä¼°å™¨æ•°é‡

    > åœ¨æ‰§è¡Œå¤šåˆ†ç±»ä»»åŠ¡æ—¶ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚æ¨¡å‹è¿­ä»£10æ¬¡ï¼Œæ¨¡å‹åˆ™ä¼šæŒ‰ç…§å®é™…çš„å¤šåˆ†ç±»æ ‡ç­¾æ•°n_classeså»ºç«‹10 * n_classesä¸ªå¼±è¯„ä¼°å™¨ã€‚å¯¹äºè¿™ä¸€ç°è±¡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å±æ€§`n_estimators_`ä»¥åŠå±æ€§`estimators_`æŸ¥çœ‹åˆ°ã€‚
    >
    > å¦‚æœæ˜¯äºŒåˆ†ç±»ä»»åŠ¡ï¼Œå¦‚æœæˆ‘ä»¬è¦æ±‚æ¨¡å‹è¿­ä»£10æ¬¡ï¼Œåˆ™åªä¼šæœ‰10ä¸ªå¼±è¯„ä¼°å™¨ï¼ˆè€Œä¸æ˜¯10*2ï¼‰
    
  - `loss`
  
    - åˆ†ç±»å™¨ä¸­çš„`loss`ï¼šå­—ç¬¦ä¸²å‹ï¼Œå¯è¾“å…¥"deviance", "exponential"ï¼Œé»˜è®¤å€¼="deviance"
  
    å…¶ä¸­"deviance"ç›´è¯‘ä¸ºåå·®ï¼Œç‰¹æŒ‡é€»è¾‘å›å½’çš„æŸå¤±å‡½æ•°â€”â€”äº¤å‰ç†µæŸå¤±ï¼Œè€Œ"exponential"åˆ™ç‰¹æŒ‡AdaBoostä¸­ä½¿ç”¨çš„æŒ‡æ•°æŸå¤±å‡½æ•°ã€‚å¯¹ä»»æ„æ ·æœ¬$i$è€Œè¨€ï¼Œ$y_i$ä¸ºçœŸå®æ ‡ç­¾ï¼Œ$\hat{y_i}$ä¸ºé¢„æµ‹æ ‡ç­¾ï¼Œ$H(x_i)$ä¸ºé›†æˆç®—æ³•è¾“å‡ºç»“æœï¼Œ$p(x_i)$ä¸ºåŸºäº$H(x_i)$å’Œsigmoid/softmaxå‡½æ•°è®¡ç®—çš„æ¦‚ç‡å€¼ã€‚åˆ™å„ä¸ªæŸå¤±çš„è¡¨è¾¾å¼ä¸ºï¼š
  
    > åˆ†ç±»æŸå¤±å‡½æ•°
    >
    > **äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±**â€”â€”<br><br>
    > $$L = -\left( y\log p(x) + (1 - y)\log(1 - p(x)) \right)$$
    >
    > <br>æ³¨æ„ï¼Œlogå½“ä¸­è¾“å…¥çš„ä¸€å®šæ˜¯æ¦‚ç‡å€¼ã€‚å¯¹äºé€»è¾‘å›å½’æ¥è¯´ï¼Œæ¦‚ç‡å°±æ˜¯ç®—æ³•çš„è¾“å‡ºï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è®¤ä¸ºé€»è¾‘å›å½’ä¸­$p = H(x)$ï¼Œä½†å¯¹äºGBDTæ¥è¯´ï¼Œ$p(x_i) = Sigmoid(H(x_i))$ï¼Œè¿™ä¸€ç‚¹ä¸€å®šè¦æ³¨æ„ã€‚
    >
    > <br>
    >
    > **å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±**ï¼Œæ€»å…±æœ‰Kä¸ªç±»åˆ«â€”â€”<br><br>
    >
    > $$L = -\sum_{k=1}^Ky^*_k\log(P^k(x))$$
    >
    > å…¶ä¸­ï¼Œ$P^k(x)$æ˜¯æ¦‚ç‡å€¼ï¼Œå¯¹äºå¤šåˆ†ç±»GBDTæ¥è¯´ï¼Œ$p^k(x) = Softmax(H^k(x))$ã€‚$y^*$æ˜¯ç”±çœŸå®æ ‡ç­¾è½¬åŒ–åçš„å‘é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨3åˆ†ç±»æƒ…å†µä¸‹ï¼ŒçœŸå®æ ‡ç­¾$y_i$ä¸º2æ—¶ï¼Œ$y^*$ä¸º[$y^*_{1}$,$y^*_{2}$,$y^*_{3}$]ï¼Œå–å€¼åˆ†åˆ«ä¸ºï¼š
    >
    > 
    >
    > | $y^*_{1}$ | $y^*_{2}$ | $y^*_{3}$ |
    > | :-------: | :-------: | :-------: |
    > |    $0$    |    $1$    |    $0$    |
    >
    > **äºŒåˆ†ç±»æŒ‡æ•°æŸå¤±**â€”â€”<br><br>
    > $$L = e^{-yH(x)}$$<br>
    >
    > **å¤šåˆ†ç±»æŒ‡æ•°æŸå¤±**ï¼Œæ€»å…±æœ‰Kä¸ªç±»åˆ«â€”â€”<br><br>
    >
    > $$
    > \begin{aligned}
    > L &=exp \left( -\frac{1}{K}\boldsymbol{y^* Â· H^*(x)} \right) \\ 
    > & = exp \left( -\frac{1}{K}(y^1H^1(x)+y^2H^2(x) \ + \  ... + y^kH^k(x)) \right)
    > \end{aligned}
    > $$<br>
    >
    > ä¸€èˆ¬æ¢¯åº¦æå‡ï¼ˆGBMachineï¼‰åˆ†ç±»å™¨é»˜è®¤ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œå¦‚æœä½¿ç”¨æŒ‡æ•°æŸå¤±ï¼Œåˆ™ç›¸å½“äºæ‰§è¡Œæ²¡æœ‰æƒé‡è°ƒæ•´çš„AdaBoostç®—æ³•ï¼ˆæå‡æ ‘æ˜¯ç¼©å°ä¸Šä¸€è½®è¿­ä»£äº§ç”Ÿçš„è¯¯å·®ï¼ŒAdaBoostæ‰æ˜¯è°ƒæ•´æ ·æœ¬æƒé‡ï¼‰ã€‚
  
    - å›å½’å™¨ä¸­çš„`loss`ï¼šå­—ç¬¦ä¸²å‹ï¼Œå¯è¾“å…¥{"squared_error", "absolute_error", "huber", "quantile"}ï¼Œé»˜è®¤å€¼="squared_error"
  
      å…¶ä¸­'squared_error'æ˜¯æŒ‡å›å½’çš„å¹³æ–¹è¯¯å·®ï¼Œ'absolute_error'æŒ‡çš„æ˜¯å›å½’çš„ç»å¯¹è¯¯å·®ï¼Œè¿™æ˜¯ä¸€ä¸ªé²æ£’çš„æŸå¤±å‡½æ•°ã€‚'huber'æ˜¯ä»¥ä¸Šä¸¤è€…çš„ç»“åˆã€‚'quantile'åˆ™è¡¨ç¤ºä½¿ç”¨åˆ†ä½æ•°å›å½’ä¸­çš„å¼¹çƒæŸå¤±pinball_lossã€‚å¯¹ä»»æ„æ ·æœ¬$i$è€Œè¨€ï¼Œ$y_i$ä¸ºçœŸå®æ ‡ç­¾ï¼Œ$H(x_i)$ä¸ºé¢„æµ‹æ ‡ç­¾
  
      > **å¹³æ–¹è¯¯å·®**â€”â€”<br><br>
      >
      > $$L = \sum{(y_i - H(x_i))^2}$$
      >
      > <br>
      >
      > **ç»å¯¹è¯¯å·®**â€”â€”<br><br>
      >
      > $$L = \sum{|y_i - H(x_i)|}$$
      >
      > <br>
      >
      > **HuberæŸå¤±**â€”â€”
      >
      > $$L = \sum{l(y_i,H(x_i))}$$
      >
      > å…¶ä¸­$$l = \begin{split} 
      > \begin{cases}\frac{1}{2}(y_i - H(x_i))^2, & |y_i - H(x_i)|\leq\alpha \\
      > \alpha(|y_i - H(x_i)|-\frac{\alpha}{2}),& |y_i - H(x_i)|>\alpha \end{cases}\end{split}, \space \space \alpha \in (0, 1)$$
      >
      > <br>
      >
      > **quantileæŸå¤±**â€”â€”
      >
      > $$L = \sum{l(y_i,H(x_i))}$$
      >
      > å…¶ä¸­$$l = \begin{split} 
      > \begin{cases}
      >     \alpha (y_i - H(x_i)), & y_i - H(x_i) > 0 \\
      >     0,    & y_i - H(x_i) = 0 \\
      >     (1-\alpha) (y_i - H(x_i)), & y_i - H(x_i) < 0
      > \end{cases}\end{split}, \space \space \alpha \in (0, 1)$$
      >
      > å…¶ä¸­$\alpha$æ˜¯éœ€è¦æˆ‘ä»¬è‡ªå·±è®¾ç½®çš„è¶…å‚æ•°ï¼Œç”±å‚æ•°`alpha`æ§åˆ¶ã€‚åœ¨huberæŸå¤±ä¸­ï¼Œalphaæ˜¯é˜ˆå€¼ï¼Œ**åœ¨quantileæŸå¤±ä¸­ï¼Œalphaç”¨äºè¾…åŠ©è®¡ç®—æŸå¤±å‡½æ•°çš„è¾“å‡ºç»“æœï¼Œé»˜è®¤ä¸º0.9**ã€‚
  
    > å¦‚ä½•é€‰æ‹©æŸå¤±å‡½æ•°
    >
    > - **å½“é«˜åº¦å…³æ³¨ç¦»ç¾¤å€¼ã€å¹¶ä¸”å¸Œæœ›åŠªåŠ›å°†ç¦»ç¾¤å€¼é¢„æµ‹æ­£ç¡®æ—¶ï¼Œé€‰æ‹©å¹³æ–¹è¯¯å·®**<br><br>
    > è¿™åœ¨å·¥ä¸šä¸­æ˜¯å¤§éƒ¨åˆ†çš„æƒ…å†µã€‚åœ¨å®é™…è¿›è¡Œé¢„æµ‹æ—¶ï¼Œç¦»ç¾¤å€¼å¾€å¾€æ¯”è¾ƒéš¾ä»¥é¢„æµ‹ï¼Œå› æ­¤ç¦»ç¾¤æ ·æœ¬çš„é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ä¸€èˆ¬ä¼šè¾ƒå¤§ã€‚MSEä½œä¸ºé¢„æµ‹å€¼å’ŒçœŸå®å€¼å·®å€¼çš„å¹³æ–¹ï¼Œä¼šæ”¾å¤§ç¦»ç¾¤å€¼çš„å½±å“ï¼Œä¼šè®©ç®—æ³•æ›´åŠ å‘å­¦ä¹ ç¦»ç¾¤å€¼çš„æ–¹å‘è¿›åŒ–ï¼Œè¿™å¯ä»¥å¸®åŠ©ç®—æ³•æ›´å¥½åœ°é¢„æµ‹ç¦»ç¾¤å€¼ã€‚
    >
    > - **åŠªåŠ›æ’é™¤ç¦»ç¾¤å€¼çš„å½±å“ã€æ›´å…³æ³¨éç¦»ç¾¤å€¼çš„æ—¶å€™ï¼Œé€‰æ‹©ç»å¯¹è¯¯å·®**<br><br>
    > MAEå¯¹ä¸€åˆ‡æ ·æœ¬éƒ½ä¸€è§†åŒä»ï¼Œå¯¹æ‰€æœ‰çš„å·®å¼‚éƒ½åªæ±‚ç»å¯¹å€¼ï¼Œå› æ­¤ä¼šä¿ç•™æ ·æœ¬å·®å¼‚æœ€åŸå§‹çš„çŠ¶æ€ã€‚ç›¸æ¯”å…¶MSEï¼ŒMAEå¯¹ç¦»ç¾¤å€¼ä¸æ•æ„Ÿï¼Œè¿™å¯ä»¥æœ‰æ•ˆåœ°é™ä½GBDTåœ¨ç¦»ç¾¤å€¼ä¸Šçš„æ³¨æ„åŠ›ã€‚
    >
    > - **è¯•å›¾å¹³è¡¡ç¦»ç¾¤å€¼ä¸éç¦»ç¾¤å€¼ã€æ²¡æœ‰åå¥½æ—¶ï¼Œé€‰æ‹©Huberæˆ–è€…Quantileloss**<br><br>
    >   HuberlossæŸå¤±ç»“åˆäº†MSEä¸MAEï¼Œåœ¨Huberçš„å…¬å¼ä¸­ï¼Œå½“é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å·®å¼‚å¤§äºé˜ˆå€¼æ—¶ï¼Œåˆ™å–ç»å¯¹å€¼ï¼Œå°äºé˜ˆå€¼æ—¶ï¼Œåˆ™å–å¹³æ–¹ã€‚åœ¨çœŸå®æ•°æ®ä¸­ï¼Œéƒ¨åˆ†ç¦»ç¾¤å€¼çš„å·®å¼‚ä¼šå¤§äºé˜ˆå€¼ï¼Œéƒ¨åˆ†ç¦»ç¾¤å€¼çš„å·®å¼‚ä¼šå°äºé˜ˆå€¼ï¼Œå› æ­¤æ¯”èµ·å…¨éƒ¨å–ç»å¯¹å€¼çš„MAEï¼ŒHuberlossä¼šå°†éƒ¨åˆ†ç¦»ç¾¤å€¼çš„çœŸå®é¢„æµ‹å·®å¼‚æ±‚å¹³æ–¹ï¼Œç›¸å½“äºæ”¾å¤§äº†ç¦»ç¾¤å€¼çš„å½±å“ï¼ˆä½†è¿™ç§å½±å“åˆä¸åƒåœ¨MSEé‚£æ ·å¤§ï¼‰ã€‚**å› æ­¤HuberLossæ˜¯ä½äºMSEå’ŒMAEä¹‹é—´çš„ã€å¯¹ç¦»ç¾¤å€¼ç›¸å¯¹ä¸æ•æ„Ÿçš„æŸå¤±**ã€‚
  
- å¼±è¯„ä¼°å™¨ç»“æ„

  - `max_depth`:åœ¨åŸå§‹AdaBoostç†è®ºä¸­ï¼ŒAdaBoostä¸­ä½¿ç”¨çš„å¼±åˆ†ç±»å™¨éƒ½æ˜¯æœ€å¤§æ·±åº¦ä¸º1çš„æ ‘æ¡©æˆ–æœ€å¤§æ·±åº¦ä¸º3çš„å°æ ‘è‹—ï¼Œå› æ­¤åŸºäºAdaBoostæ”¹è¿›çš„å…¶ä»–Boostingç®—æ³•ä¹Ÿæœ‰è¯¥é™åˆ¶ï¼Œå³é»˜è®¤å¼±è¯„ä¼°å™¨çš„æœ€å¤§æ·±åº¦ä¸€èˆ¬æ˜¯ä¸€ä¸ªè¾ƒå°çš„æ•°å­—**ã€‚**å¯¹GBDTæ¥è¯´ï¼Œæ— è®ºæ˜¯åˆ†ç±»å™¨è¿˜æ˜¯å›å½’å™¨ï¼Œé»˜è®¤çš„å¼±è¯„ä¼°å™¨æœ€å¤§æ·±åº¦éƒ½ä¸º3ï¼Œå› æ­¤GBDTé»˜è®¤å°±å¯¹å¼±è¯„ä¼°å™¨æœ‰å¼ºåŠ›çš„å‰ªææœºåˆ¶ã€‚

    å½“éšæœºæ£®æ—å¤„äºè¿‡æ‹ŸåˆçŠ¶æ€æ—¶ï¼Œè¿˜å¯é€šè¿‡é™ä½å¼±è¯„ä¼°å™¨å¤æ‚åº¦çš„æ‰‹æ®µï¼ˆ`max_depth`ä¸ºNoneï¼‰æ§åˆ¶è¿‡æ‹Ÿåˆï¼Œä½†GBDTç­‰Boostingç®—æ³•å¤„äºè¿‡æ‹ŸåˆçŠ¶æ€æ—¶ï¼Œä¾¿åªèƒ½ä»æ•°æ®ä¸Šä¸‹æ‰‹æ§åˆ¶è¿‡æ‹Ÿåˆäº†ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å‚æ•°`max_features`ï¼Œåœ¨GBDTä¸­å…¶é»˜è®¤å€¼ä¸ºNoneï¼‰ï¼Œæ¯•ç«Ÿå½“`max_depth`å·²ç»éå¸¸å°æ—¶ï¼Œå…¶ä»–ç²¾å‰ªæçš„å‚æ•°å¦‚`min_impurity_decrease`ä¸€èˆ¬å‘æŒ¥ä¸äº†å¤ªå¤§çš„ä½œç”¨ã€‚

  - `criterion`:**æ ‘åˆ†ææ—¶æ‰€ä½¿ç”¨çš„ä¸çº¯åº¦è¡¡é‡æŒ‡æ ‡**.ä¸çº¯åº¦çš„è¡¡é‡æŒ‡æ ‡æœ‰2ä¸ªï¼šå¼—é‡Œå¾·æ›¼å‡æ–¹è¯¯å·®friedman_mseä¸å¹³æ–¹è¯¯å·®squared_error

    > **é€šå¸¸æ¥è¯´ï¼Œæˆ‘ä»¬æ±‚è§£çˆ¶èŠ‚ç‚¹çš„ä¸çº¯åº¦ä¸å·¦å³èŠ‚ç‚¹ä¸çº¯åº¦ä¹‹å’Œä¹‹é—´çš„å·®å€¼ï¼Œè¿™ä¸ªå·®å€¼è¢«ç§°ä¸ºä¸çº¯åº¦ä¸‹é™é‡**(impurity decrease)ã€‚ä¸çº¯åº¦çš„ä¸‹é™é‡è¶Šå¤§ï¼Œè¯¥åˆ†æå¯¹äºé™ä½ä¸çº¯åº¦çš„è´¡çŒ®è¶Šå¤§ã€‚

    > **åŸºäºå¼—é‡Œå¾·æ›¼å‡æ–¹è¯¯å·®çš„ä¸çº¯åº¦ä¸‹é™é‡**<br>
    >
    > $$\frac{w_lw_r}{w_l \space + \space w_r} * \left( \frac{\sum_l{(r_i - \hat{y_i})^2}}{w_l} - \frac{\sum_r{(r_i - \hat{y_i})^2}}{w_r}\right)^2$$
    >
    > å…¶ä¸­$w$æ˜¯å·¦å³å¶å­èŠ‚ç‚¹ä¸Šçš„æ ·æœ¬é‡ï¼Œå½“æˆ‘ä»¬å¯¹æ ·æœ¬æœ‰æƒé‡è°ƒæ•´æ—¶ï¼Œ$w$åˆ™æ˜¯å¶å­èŠ‚ç‚¹ä¸Šçš„æ ·æœ¬æƒé‡ã€‚$r_i$å¤§å¤šæ•°æ—¶å€™æ˜¯æ ·æœ¬iä¸Šçš„æ®‹å·®ï¼ˆçˆ¶èŠ‚ç‚¹ä¸­æ ·æœ¬içš„é¢„æµ‹ç»“æœä¸æ ·æœ¬içš„çœŸå®æ ‡ç­¾ä¹‹å·®ï¼‰ï¼Œä¹Ÿå¯èƒ½æ˜¯å…¶ä»–è¡¡é‡é¢„æµ‹ä¸çœŸå®æ ‡ç­¾å·®å¼‚çš„æŒ‡æ ‡ï¼Œ$\hat{y_i}$æ˜¯æ ·æœ¬iåœ¨å½“å‰å­èŠ‚ç‚¹ä¸‹çš„é¢„æµ‹å€¼ã€‚æ‰€ä»¥è¿™ä¸ªå…¬å¼å…¶å®å¯ä»¥è§£è¯»æˆï¼šå·¦å³å¶å­èŠ‚ç‚¹ä¸Šæ ·æœ¬é‡çš„è°ƒå’Œå¹³å‡ * (å·¦å¶å­èŠ‚ç‚¹ä¸Šå‡æ–¹è¯¯å·® - å³å¶å­èŠ‚ç‚¹ä¸Šçš„å‡æ–¹è¯¯å·®)^2
    >
    > 
    >
    > æ ¹æ®è®ºæ–‡ä¸­çš„æè¿°ï¼Œ**å¼—é‡Œå¾·æ›¼å‡æ–¹è¯¯å·®ä½¿ç”¨è°ƒå’Œå¹³å‡æ•°ï¼ˆåˆ†å­ä¸Šç›¸ä¹˜åˆ†æ¯ä¸Šç›¸åŠ ï¼‰æ¥æ§åˆ¶å·¦å³å¶å­èŠ‚ç‚¹ä¸Šçš„æ ·æœ¬æ•°é‡ï¼Œç›¸æ¯”æ™®é€šåœ°æ±‚å‡å€¼ï¼Œè°ƒå’Œå¹³å‡å¿…é¡»åœ¨å·¦å³å¶å­èŠ‚ç‚¹ä¸Šçš„æ ·æœ¬é‡/æ ·æœ¬æƒé‡ç›¸å·®ä¸å¤§çš„æƒ…å†µä¸‹æ‰èƒ½å–å¾—è¾ƒå¤§çš„å€¼**ï¼ˆF1 scoreä¹Ÿæ˜¯ç”¨åŒæ ·çš„æ–¹å¼æ¥è°ƒèŠ‚Precisionå’Œrecallï¼‰ã€‚è¿™ç§æ–¹å¼å¯ä»¥ä»¤ä¸çº¯åº¦çš„ä¸‹é™å¾—æ›´å¿«ï¼Œè®©æ•´ä½“åˆ†æçš„æ•ˆç‡æ›´é«˜ã€‚
    >
    > åŒæ—¶ï¼Œåœ¨å†³ç­–æ ‘è¿›è¡Œåˆ†ææ—¶ï¼Œä¸€èˆ¬ä¸å¤ªå¯èƒ½ç›´æ¥å°†æ‰€æœ‰æ ·æœ¬åˆ†æˆä¸¤ä¸ªä¸çº¯åº¦éå¸¸ä½çš„å­é›†ï¼ˆåˆ†åˆ«ä½äºä¸¤ç‰‡å¶å­ä¸Šï¼‰;**ç›¸å¯¹çš„ï¼Œæ ‘ä¼šåå‘äºå»ºç«‹ä¸€ä¸ªä¸çº¯åº¦éå¸¸éå¸¸ä½çš„å­é›†ï¼Œç„¶åå°†å‰©ä¸‹æ— æ³•å½’å…¥è¿™ä¸ªä½ä¸çº¯åº¦å­é›†çš„æ ·æœ¬å…¨éƒ¨æ‰“åŒ…æˆå¦å¤–ä¸€ä¸ªå­é›†**ã€‚å› æ­¤ç›´æ¥ä½¿ç”¨ä¸¤ä¸ªå­é›†ä¹‹é—´çš„MSEå·®è·æ¥è¡¡é‡ä¸çº¯åº¦çš„ä¸‹é™é‡éå¸¸èªæ˜ï¼Œå¦‚æœä¸¤ä¸ªå­é›†ä¹‹é—´çš„MSEå·®å¼‚å¾ˆå¤§ï¼Œåˆ™è¯´æ˜å…¶ä¸­ä¸€ä¸ªå­é›†çš„MSEä¸€å®šå¾ˆå°ï¼Œå¯¹æ•´ä½“åˆ†ææ¥è¯´æ˜¯æ›´æœ‰åˆ©çš„ã€‚

    > **å¹³æ–¹è¯¯å·®çš„ä¸çº¯åº¦ä¸‹é™é‡**
    >
    > $$\frac{\sum_p{(r_i - \hat{y_i})^2}}{w_l + w_r} - (\frac{w_l}{w_l+w_r} * \sum_l{(r_i - \hat{y_i})^2} + \frac{w_r}{w_l+w_r} * \sum_r{(r_i - \hat{y_i})^2})$$<br>

    

    > **å¤§éƒ¨åˆ†æ—¶å€™ï¼Œä½¿ç”¨å¼—é‡Œå¾·æ›¼å‡æ–¹è¯¯å·®å¯ä»¥è®©æ¢¯åº¦æå‡æ ‘å¾—åˆ°å¾ˆå¥½çš„ç»“æœ**ï¼Œå› æ­¤GBDTçš„é»˜è®¤å‚æ•°å°±æ˜¯Friedman_mseã€‚ä¸è¿‡è®¸å¤šæ—¶å€™ï¼Œæˆ‘ä»¬ä¼šå‘ç°åŸºäºå¹³æ–¹è¯¯å·®çš„åˆ†å‰²ä¸åŸºäºå¼—é‡Œå¾·æ›¼å‡æ–¹è¯¯å·®çš„åˆ†å‰²ä¼šå¾—åˆ°ç›¸åŒçš„ç»“æœã€‚


- æå‰åœæ­¢

  > **ä»€ä¹ˆæ—¶å€™ä½¿ç”¨æå‰åœæ­¢å‘¢ï¼Ÿä¸€èˆ¬æœ‰ä»¥ä¸‹å‡ ç§åœºæ™¯ï¼š**
  >
  > - **å½“æ•°æ®é‡éå¸¸å¤§ï¼Œè‚‰çœ¼å¯è§è®­ç»ƒé€Ÿåº¦ä¼šéå¸¸ç¼“æ…¢çš„æ—¶å€™ï¼Œå¼€å¯æå‰åœæ­¢ä»¥èŠ‚çº¦è¿ç®—æ—¶é—´**
  > - **n_estimatorså‚æ•°èŒƒå›´æå¹¿ã€å¯èƒ½æ¶‰åŠåˆ°éœ€è¦500~1000æ£µæ ‘æ—¶ï¼Œå¼€å¯æå‰åœæ­¢æ¥å¯»æ‰¾å¯èƒ½çš„æ›´å°çš„n_estimatorså–å€¼**
  > - **å½“æ•°æ®é‡éå¸¸å°ï¼Œæ¨¡å‹å¾ˆå¯èƒ½å¿«é€Ÿé™·å…¥è¿‡æ‹ŸåˆçŠ¶å†µæ—¶ï¼Œå¼€å¯æå‰åœæ­¢æ¥é˜²æ­¢è¿‡æ‹Ÿåˆ**

  > **è¿‡æ‹Ÿåˆ VS æ¬ æ‹Ÿåˆ**
  >
  > åœ¨å®é™…è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåˆšå¼€å§‹è®­ç»ƒæ—¶ï¼Œæµ‹è¯•é›†å’Œè®­ç»ƒé›†ä¸Šçš„æŸå¤±ä¸€èˆ¬éƒ½å¾ˆé«˜ï¼ˆæœ‰æ—¶ï¼Œè®­ç»ƒé›†ä¸Šçš„æŸå¤±ç”šè‡³æ¯”æµ‹è¯•é›†ä¸Šçš„æŸå¤±è¿˜é«˜ï¼Œè¿™è¯´æ˜æ¨¡å‹ä¸¥é‡æ¬ è®­ç»ƒï¼‰ï¼Œä½†éšç€è®­ç»ƒæ¬¡æ•°çš„å¢å¤šï¼Œä¸¤ç§æŸå¤±éƒ½ä¼šå¼€å§‹å¿«é€Ÿä¸‹é™ï¼Œ**ä¸€èˆ¬è®­ç»ƒé›†ä¸‹é™å¾—æ›´å¿«ï¼Œæµ‹è¯•é›†ä¸‹é™å¾—ç¼“æ…¢**ã€‚ç›´åˆ°æŸä¸€æ¬¡è¿­ä»£æ—¶ï¼Œæ— è®ºæˆ‘ä»¬å¦‚ä½•è®­ç»ƒï¼Œæµ‹è¯•é›†ä¸Šçš„æŸå¤±éƒ½ä¸å†ä¸‹é™ï¼Œç”šè‡³å¼€å§‹å‡é«˜ï¼Œæ­¤æ—¶æˆ‘ä»¬å°±éœ€è¦è®©è¿­ä»£åœä¸‹ã€‚
  >
  > å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸‹å›¾ä¸­æ¨ªåæ ‡ä¸ºè¿­ä»£æ¬¡æ•°ï¼Œçºµåæ ‡ä¸ºæŸå¤±å‡½æ•°çš„å€¼ã€‚å½“æµ‹è¯•é›†ä¸Šçš„æŸå¤±ä¸å†ä¸‹é™ã€æŒç»­ä¿æŒå¹³ç¨³æ—¶ï¼Œè‹¥ç»§ç»­è®­ç»ƒä¼šæµªè´¹è®­ç»ƒèµ„æºï¼Œè¿­ä»£ä¸‹å»æ¨¡å‹ä¹Ÿä¼šåœæ»ä¸å‰ï¼Œå› æ­¤éœ€è¦åœæ­¢ï¼ˆå·¦å›¾ï¼‰ã€‚å½“æµ‹è¯•é›†ä¸Šçš„æŸå¤±å¼€å§‹å‡é«˜æ—¶ï¼Œå¾€å¾€è®­ç»ƒé›†ä¸Šçš„æŸå¤±è¿˜æ˜¯åœ¨ç¨³æ­¥ä¸‹é™ï¼Œç»§ç»­è¿­ä»£ä¸‹å»å°±ä¼šé€ æˆè®­ç»ƒé›†æŸå¤±æ¯”æµ‹è¯•é›†æŸå¤±å°å¾ˆå¤šçš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¿‡æ‹Ÿåˆï¼ˆå³ä¾§ï¼‰ï¼Œä¹Ÿéœ€è¦æå‰åœæ­¢ã€‚åœ¨è¿‡æ‹Ÿåˆä¹‹å‰åŠæ—¶åœæ­¢ï¼Œèƒ½å¤Ÿé˜²æ­¢æ¨¡å‹è¢«è¿­ä»£åˆ°è¿‡æ‹ŸåˆçŠ¶å†µä¸‹ã€‚
  >
  > ![53](C:\Users\AlexChan\Documents\XTU\æèˆª-æœºå™¨å­¦ä¹ æ–¹æ³•\GBDT\blogç¬”è®°\markdownç…§ç‰‡\53.png)

  - `validation_fraction`ï¼šä»è®­ç»ƒé›†ä¸­æå–å‡ºã€ç”¨äºæå‰åœæ­¢çš„éªŒè¯é›†æ•°æ®å æ¯”ï¼Œå€¼åŸŸä¸º[0,1]ã€‚
  - `n_iter_no_change`ï¼šå½“éªŒè¯é›†ä¸Šçš„æŸå¤±å‡½æ•°å€¼è¿ç»­n_iter_no_changeæ¬¡æ²¡æœ‰ä¸‹é™æˆ–ä¸‹é™é‡ä¸è¾¾é˜ˆå€¼`tol`æ—¶ï¼Œåˆ™è§¦å‘æå‰åœæ­¢ã€‚å¹³æ—¶åˆ™è®¾ç½®ä¸ºNoneï¼Œè¡¨ç¤ºä¸è¿›è¡Œæå‰åœæ­¢ã€‚(å³ä¾¿æˆ‘ä»¬è§„å®šçš„`n_estimators`æˆ–è€…`max_iter`ä¸­çš„æ•°é‡è¿˜æ²¡æœ‰è¢«ç”¨å®Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®¤ä¸ºç®—æ³•å·²ç»éå¸¸æ¥è¿‘â€œæ”¶æ•›â€è€Œå°†è®­ç»ƒåœä¸‹ã€‚è¿™ç§æœºåˆ¶å°±æ˜¯æå‰åœæ­¢æœºåˆ¶Early Stopping)
  - `tol`ï¼šæŸå¤±å‡½æ•°ä¸‹é™çš„é˜ˆå€¼ï¼Œé»˜è®¤å€¼ä¸º1e-4ï¼Œä¹Ÿå¯è°ƒæ•´ä¸ºå…¶ä»–æµ®ç‚¹æ•°æ¥è§‚å¯Ÿæå‰åœæ­¢çš„æƒ…å†µã€‚

  > æå‰åœæ­¢æ¡ä»¶è¢«è§¦å‘åï¼Œæ¢¯åº¦æå‡æ ‘ä¼šåœæ­¢è®­ç»ƒï¼Œå³åœæ­¢å»ºæ ‘ã€‚å› æ­¤ï¼Œå½“æå‰åœæ­¢åŠŸèƒ½è¢«è®¾ç½®æ‰“å¼€æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨å±æ€§`n_estimators_`è°ƒå‡ºçš„ç»“æœå¾ˆå¯èƒ½ä¸è¶³æˆ‘ä»¬è®¾ç½®çš„`n_estimators`ï¼Œå±æ€§`estimators_`ä¸­çš„æ ‘æ•°é‡ä¹Ÿå¯èƒ½å˜å¾—æ›´å°‘

- å¼±è¯„ä¼°å™¨çš„è®­ç»ƒæ•°æ®

  > å—åˆ°éšæœºæ£®æ—çš„å¯å‘ï¼Œ**æ¢¯åº¦æå‡æ ‘åœ¨æ¯æ¬¡å»ºæ ‘ä¹‹å‰ï¼Œä¹Ÿå…è®¸æ¨¡å‹å¯¹äºæ•°æ®å’Œç‰¹å¾è¿›è¡Œéšæœºæœ‰æ”¾å›æŠ½æ ·ï¼Œæ„å»ºä¸åŸå§‹æ•°æ®é›†ç›¸åŒæ•°æ®é‡çš„è‡ªåŠ©é›†**ã€‚**åœ¨æ¢¯åº¦æå‡æ ‘çš„åŸç†å½“ä¸­ï¼Œå½“æ¯æ¬¡å»ºæ ‘ä¹‹å‰è¿›è¡ŒéšæœºæŠ½æ ·æ—¶ï¼Œè¿™ç§æ¢¯åº¦æå‡æ ‘å«åšéšæœºæå‡æ ‘ï¼ˆStochastic Gradient Boostingï¼‰ã€‚ç›¸æ¯”èµ·ä¼ ç»Ÿçš„æ¢¯åº¦æå‡æ ‘ï¼Œéšæœºæå‡æ ‘è¾“å‡ºçš„ç»“æœå¾€å¾€æ–¹å·®æ›´ä½ï¼Œä½†åå·®ç•¥é«˜**ã€‚å¦‚æœæˆ‘ä»¬å‘ç°GBDTçš„ç»“æœé«˜åº¦ä¸ç¨³å®šï¼Œåˆ™å¯ä»¥å°è¯•ä½¿ç”¨éšæœºæå‡æ ‘ã€‚
  >
  > > è§£é‡Šæ–¹å·®ä½åå·®é«˜çš„åŸå› ï¼š
  > >
  > > ç”±äºæ˜¯å¼±è¯„ä¼°å™¨ï¼Œä¹Ÿå°±æ˜¯ç®€å•æ¨¡å‹ï¼Œç‰¹ç‚¹æ˜¯åå·®é«˜æ–¹å·®ä½ä¹Ÿå°±æ˜¯æ¬ æ‹Ÿåˆï¼›ç”±äºéšæœºæå‡æ ‘åœ¨æ¯ä¸€è½®ä½¿ç”¨çš„æ˜¯æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ï¼Œå› æ­¤æ¯æ£µæ ‘çš„æ„å»ºä¸ä¼šè¿‡åˆ†ä¾èµ–äºç‰¹å®šçš„æ•°æ®ç‰¹å¾æˆ–å™ªå£°ï¼Œä»è€Œé™ä½äº†æ¨¡å‹æ•´ä½“çš„æ–¹å·®ï¼›åŒæ—¶ï¼Œç”±äºä¸æ˜¯æ¯æ¬¡éƒ½ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯æ²¡æœ‰è¢«æ¨¡å‹å®Œå…¨å­¦ä¹ åˆ°ï¼Œè¿™å¯èƒ½ä¼šè½»å¾®å¢åŠ æ¨¡å‹çš„åå·®ã€‚æ¢è¨€ä¹‹ï¼Œæ¨¡å‹å¯èƒ½ä¸ä¼šå®Œå…¨æ•æ‰åˆ°æ•°æ®ä¸­çš„æ‰€æœ‰æ¨¡å¼ï¼Œä»è€Œåœ¨é¢„æµ‹æ—¶äº§ç”Ÿä¸€å®šç¨‹åº¦çš„ç³»ç»Ÿè¯¯å·®

  - `subsample`ï¼šæ¯æ¬¡å»ºæ ‘ä¹‹å‰ï¼Œä»å…¨æ•°æ®é›†ä¸­è¿›è¡Œæœ‰æ”¾å›éšæœºæŠ½æ ·çš„æ¯”ä¾‹

  - `max_features`ï¼šæ¯æ¬¡å»ºæ ‘ä¹‹å‰ï¼Œä»å…¨ç‰¹å¾ä¸­éšæœºæŠ½æ ·ç‰¹å¾è¿›è¡Œåˆ†æçš„æ¯”ä¾‹

  - `random_state`ï¼šéšæœºæ•°ç§å­ï¼Œæ§åˆ¶æ•´ä½“éšæœºæ¨¡å¼

    > åœ¨GBDTå½“ä¸­ï¼Œå¯¹æ•°æ®çš„éšæœºæœ‰æ”¾å›æŠ½æ ·æ¯”ä¾‹ç”±å‚æ•°`subsample`ç¡®å®šï¼Œå½“è¯¥å‚æ•°è¢«è®¾ç½®ä¸º1æ—¶ï¼Œåˆ™ä¸è¿›è¡ŒæŠ½æ ·ï¼Œç›´æ¥ä½¿ç”¨å…¨éƒ¨æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚å½“è¯¥å‚æ•°è¢«è®¾ç½®ä¸º(0,1)ä¹‹é—´çš„æ•°å­—æ—¶ï¼Œåˆ™ä½¿ç”¨éšæœºæå‡æ ‘ï¼Œåœ¨æ¯è½®å»ºæ ‘ä¹‹å‰å¯¹æ ·æœ¬è¿›è¡ŒæŠ½æ ·ã€‚å¯¹ç‰¹å¾çš„æœ‰æ”¾å›æŠ½æ ·æ¯”ä¾‹ç”±å‚æ•°`max_features`ç¡®å®šï¼Œéšæœºæ¨¡å¼åˆ™ç”±å‚æ•°`random_state`ç¡®å®šï¼Œè¿™ä¸¤ä¸ªå‚æ•°åœ¨GBDTå½“ä¸­çš„ä½¿ç”¨è§„åˆ™éƒ½ä¸éšæœºæ£®æ—ä¸­å®Œå…¨ä¸€è‡´ã€‚
    >
    > > éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœ`subsample`<1ï¼Œå³å­˜åœ¨æœ‰æ”¾å›éšæœºæŠ½æ ·æ—¶ï¼Œå½“æ•°æ®é‡è¶³å¤Ÿå¤§ã€æŠ½æ ·æ¬¡æ•°è¶³å¤Ÿå¤šæ—¶ï¼Œå¤§çº¦ä¼šæœ‰37%çš„æ•°æ®è¢«é—æ¼åœ¨â€œè¢‹å¤–â€ï¼ˆout of bagï¼‰æ²¡æœ‰å‚ä¸è®­ç»ƒã€‚åœ¨éšæœºæ£®æ—è¯¾ç¨‹å½“ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†åœ°è¯æ˜äº†37%çš„ç”±æ¥ï¼Œå¹¶ä¸”ä½¿ç”¨è¿™37%çš„è¢‹å¤–æ•°æ®ä½œä¸ºéªŒè¯æ•°æ®ï¼Œå¯¹éšæœºæ£®æ—çš„ç»“æœè¿›è¡ŒéªŒè¯ã€‚åœ¨GBDTå½“ä¸­ï¼Œå½“æœ‰æ”¾å›éšæœºæŠ½æ ·å‘ç”Ÿæ—¶ï¼Œè‡ªç„¶ä¹Ÿå­˜åœ¨éƒ¨åˆ†è¢‹å¤–æ•°æ®æ²¡æœ‰å‚ä¸è®­ç»ƒã€‚è¿™éƒ¨åˆ†æ•°æ®åœ¨GBDTä¸­è¢«ç”¨äºå¯¹æ¯ä¸€ä¸ªå¼±è¯„ä¼°å™¨çš„å»ºç«‹ç»“æœè¿›è¡ŒéªŒè¯ã€‚

  - oob_improvementï¼šæ¯æ¬¡å»ºæ ‘ä¹‹åç›¸å¯¹äºä¸Šä¸€æ¬¡è¢‹å¤–åˆ†æ•°çš„å¢å‡

  - train_score_ï¼šæ¯æ¬¡å»ºæ ‘ä¹‹åç›¸å¯¹äºä¸Šä¸€æ¬¡éªŒè¯æ—¶è¢‹å†…åˆ†æ•°çš„å¢å‡

    > **æ¯å»ºç«‹ä¸€æ£µæ ‘ï¼ŒGBDTå°±ä¼šä½¿ç”¨å½“å‰æ ‘çš„è¢‹å¤–æ•°æ®å¯¹å»ºç«‹æ–°æ ‘åçš„æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œä»¥æ­¤æ¥å¯¹æ¯”æ–°å»ºå¼±è¯„ä¼°å™¨åæ¨¡å‹æ•´ä½“çš„æ°´å¹³æ˜¯å¦æé«˜ï¼Œå¹¶ä¿ç•™æå‡æˆ–ä¸‹é™çš„ç»“æœ**ã€‚è¿™ä¸ªè¿‡ç¨‹ç›¸å½“äºåœ¨GBDTè¿­ä»£æ—¶ï¼Œä¸æ–­æ£€éªŒæŸå¤±å‡½æ•°çš„å€¼å¹¶æ•æ‰å…¶å˜åŒ–çš„è¶‹åŠ¿ã€‚åœ¨GBDTå½“ä¸­ï¼Œè¿™äº›è¢‹å¤–åˆ†æ•°çš„å˜åŒ–å€¼è¢«å‚¨å­˜åœ¨å±æ€§`oob_improvement_`ä¸­ï¼ŒåŒæ—¶ï¼ŒGBDTè¿˜ä¼šåœ¨æ¯æ£µæ ‘çš„è®­ç»ƒæ•°æ®ä¸Šä¿ç•™è¢‹å†…åˆ†æ•°ï¼ˆin-bagï¼‰çš„å˜åŒ–ï¼Œä¸”å‚¨å­˜åœ¨å±æ€§`train_score_`å½“ä¸­ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå³ä¾¿åœ¨ä¸åšäº¤å‰éªŒè¯çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç®€å•åœ°é€šè¿‡å±æ€§`oob_improvement`ä¸å±æ€§`train_score_`æ¥è§‚å¯ŸGBDTè¿­ä»£çš„ç»“æœ

  
  
  ## GBDTçš„å‚æ•°ç©ºé—´
  
  > å¯¹ä»»æ„é›†æˆç®—æ³•è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®ä¸¤ä¸ªåŸºæœ¬äº‹å®ï¼š
  >
  > 1ã€ä¸åŒå‚æ•°å¯¹ç®—æ³•ç»“æœçš„å½±å“åŠ›å¤§å°
  > 2ã€ç¡®å®šç”¨äºæœç´¢çš„å‚æ•°ç©ºé—´
  
  å¯¹GBDTæ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å¤§è‡´å¦‚ä¸‹æ’åˆ—å„ä¸ªå‚æ•°å¯¹ç®—æ³•çš„å½±å“ï¼š
  
  |                     å½±å“åŠ›                     |                             å‚æ•°                             |
  | :--------------------------------------------: | :----------------------------------------------------------: |
  |        â­â­â­â­â­<br>å‡ ä¹æ€»æ˜¯å…·æœ‰å·¨å¤§å½±å“åŠ›         | n_estimatorsï¼ˆæ•´ä½“å­¦ä¹ èƒ½åŠ›ï¼‰<br>learning_rateï¼ˆæ•´ä½“å­¦ä¹ é€Ÿç‡ï¼‰<br>max_featuresï¼ˆéšæœºæ€§ï¼‰<br> |
  |          â­â­â­â­<br>å¤§éƒ¨åˆ†æ—¶å€™å…·æœ‰å½±å“åŠ›          | initï¼ˆåˆå§‹åŒ–ï¼‰<br>subsamplesï¼ˆéšæœºæ€§ï¼‰<br>lossï¼ˆæ•´ä½“å­¦ä¹ èƒ½åŠ›ï¼‰ |
  | â­â­<br>å¯èƒ½æœ‰å¤§å½±å“åŠ›<br>å¤§éƒ¨åˆ†æ—¶å€™å½±å“åŠ›ä¸æ˜æ˜¾ | max_depthï¼ˆç²—å‰ªæï¼‰<br>min_samples_splitï¼ˆç²¾å‰ªæï¼‰<br>min_impurity_decreaseï¼ˆç²¾å‰ªæï¼‰<br>max_leaf_nodesï¼ˆç²¾å‰ªæï¼‰<br>criterionï¼ˆåˆ†ææ•æ„Ÿåº¦ï¼‰ |
  |       â­<br>å½“æ•°æ®é‡è¶³å¤Ÿå¤§æ—¶ï¼Œå‡ ä¹æ— å½±å“        |            random_state<br>ccp_alphaï¼ˆç»“æ„é£é™©ï¼‰             |
  

> 
>
> > åœ¨éšæœºæ£®æ—ä¸­éå¸¸å…³é”®çš„`max_depth`åœ¨GBDTä¸­æ²¡æœ‰ä»€ä¹ˆåœ°ä½ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯Boostingä¸­ç‰¹æœ‰çš„è¿­ä»£å‚æ•°å­¦ä¹ ç‡`learning_rate`ã€‚åœ¨éšæœºæ£®æ—ä¸­ï¼Œæˆ‘ä»¬æ€»æ˜¯åœ¨æ„æ¨¡å‹å¤æ‚åº¦(`max_depth`)ä¸æ¨¡å‹æ•´ä½“å­¦ä¹ èƒ½åŠ›(`n_estimators`)çš„å¹³è¡¡ï¼Œå•ä¸€å¼±è¯„ä¼°å™¨çš„å¤æ‚åº¦è¶Šå¤§ï¼Œå•ä¸€å¼±è¯„ä¼°å™¨å¯¹æ¨¡å‹çš„æ•´ä½“è´¡çŒ®å°±è¶Šå¤§ï¼Œå› æ­¤éœ€è¦çš„æ ‘æ•°é‡å°±è¶Šå°‘ã€‚åœ¨Boostingç®—æ³•å½“ä¸­ï¼Œå•ä¸€å¼±è¯„ä¼°å™¨å¯¹æ•´ä½“ç®—æ³•çš„è´¡çŒ®ç”±å­¦ä¹ ç‡å‚æ•°`learning_rate`æ§åˆ¶ï¼Œä»£æ›¿äº†å¼±è¯„ä¼°å™¨å¤æ‚åº¦çš„åœ°ä½ï¼Œ**å› æ­¤Boostingç®—æ³•ä¸­æˆ‘ä»¬å¯»æ‰¾çš„æ˜¯`learning_rate`ä¸`n_estimators`çš„å¹³è¡¡**ã€‚åŒæ—¶ï¼ŒBoostingç®—æ³•å¤©ç”Ÿå°±å‡è®¾å•ä¸€å¼±è¯„ä¼°å™¨çš„èƒ½åŠ›å¾ˆå¼±ï¼Œå‚æ•°`max_depth`çš„é»˜è®¤å€¼ä¹Ÿå¾€å¾€è¾ƒå°ï¼ˆåœ¨GBDTä¸­`max_depth`çš„é»˜è®¤å€¼æ˜¯3ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•é é™ä½`max_depth`çš„å€¼æ¥å¤§è§„æ¨¡é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œæ›´éš¾ä»¥é `max_depth`æ¥æ§åˆ¶è¿‡æ‹Ÿåˆï¼Œè‡ªç„¶`max_depth`çš„å½±å“åŠ›å°±å˜å°äº†ã€‚
>
> > **ç‰¹åˆ«åœ°ï¼Œå‚æ•°`init`å¯¹GBDTçš„å½±å“å¾ˆå¤§ï¼Œå¦‚æœåœ¨å‚æ•°`init`ä¸­å¡«å…¥å…·ä½“çš„ç®—æ³•ï¼Œè¿‡æ‹Ÿåˆå¯èƒ½ä¼šå˜å¾—æ›´åŠ ä¸¥é‡**
>
> 
>
> > **å¦‚æœæ— æ³•å¯¹å¼±è¯„ä¼°å™¨è¿›è¡Œå‰ªæï¼Œæœ€å¥½çš„æ§åˆ¶è¿‡æ‹Ÿåˆçš„æ–¹æ³•å°±æ˜¯å¢åŠ éšæœºæ€§/å¤šæ ·æ€§ï¼Œå› æ­¤`max_features`å’Œ`subsample`å°±æˆä¸ºBoostingç®—æ³•ä¸­æ§åˆ¶è¿‡æ‹Ÿåˆçš„æ ¸å¿ƒæ­¦å™¨**.**æ¯”èµ·Baggingï¼ŒBoostingæ›´åŠ æ“…é•¿å¤„ç†å°æ ·æœ¬é«˜ç»´åº¦çš„æ•°æ®ï¼ˆBoostingæ›´ä¸“æ³¨äºå‰ä¸€ä¸ªæ¨¡å‹çš„é”™è¯¯ï¼Œæ›´åŠ é‡è§†åˆ†ç±»é”™è¯¯çš„æ ·æœ¬ï¼Œè€ŒBaggingæ˜¯ç‹¬ç«‹æ„å»ºæ¯ä¸€æ£µæ ‘ï¼‰ï¼Œå› ä¸ºBaggingæ•°æ®å¾ˆå®¹æ˜“åœ¨å°æ ·æœ¬æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆ**ï¼ˆä½†åœ¨å°æ ·æœ¬æ•°æ®é›†ä¸Šï¼Œç”±äºæ ·æœ¬å¤šæ ·æ€§æœ‰é™ã€æ¨¡å‹å¯èƒ½ä¼šå­¦ä¹ åˆ°æ•°æ®ä¸­çš„éšæœºå™ªå£°ï¼Œè€Œä¸æ˜¯æ½œåœ¨çš„çœŸå®æ¨¡å¼ï¼Œè¿™å°±æ˜¯è¿‡æ‹Ÿåˆã€‘ï¼‰
>
> > åœ¨GBDTå½“ä¸­ï¼Œ`max_depth`çš„è°ƒå‚æ–¹å‘æ˜¯æ”¾å¤§/åŠ æ·±ï¼Œä»¥æ¢ç©¶æ¨¡å‹æ˜¯å¦éœ€è¦æ›´é«˜çš„å•ä¸€è¯„ä¼°å™¨å¤æ‚åº¦ã€‚ç›¸å¯¹çš„åœ¨éšæœºæ£®æ—å½“ä¸­ï¼Œ`max_depth`çš„è°ƒå‚æ–¹å‘æ˜¯ç¼©å°/å‰ªæï¼Œç”¨ä»¥ç¼“è§£è¿‡æ‹Ÿåˆ
>
> > **GBDTçš„å‚æ•°ç©ºé—´å‡ ä¹ä¸ä¾èµ–äºæ ‘çš„çœŸå®ç»“æ„è¿›è¡Œè°ƒæ•´ï¼Œä¸”å¤§éƒ¨åˆ†å‚æ•°éƒ½æœ‰å›ºå®šçš„èŒƒå›´ï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦å¯¹æ— ç•Œçš„å‚æ•°ç¨ç¨æ¢ç´¢å³å¯**

> å…ˆä¼šè€ƒè™‘æ‰€æœ‰å½±å“åŠ›å·¨å¤§çš„å‚æ•°ï¼ˆ5æ˜Ÿå‚æ•°ï¼‰ï¼Œå½“ç®—åŠ›è¶³å¤Ÿ/ä¼˜åŒ–ç®—æ³•è¿è¡Œè¾ƒå¿«çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†å¤§éƒ¨åˆ†æ—¶å€™å…·æœ‰å½±å“åŠ›çš„å‚æ•°ï¼ˆ4æ˜Ÿï¼‰ä¹Ÿéƒ½åŠ å…¥å‚æ•°ç©ºé—´ï¼Œå¦‚æœæ ·æœ¬é‡è¾ƒå°ï¼Œæˆ‘ä»¬å¯èƒ½ä¸é€‰æ‹©`subsample`ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦éƒ¨åˆ†å½±å“å¼±è¯„ä¼°å™¨å¤æ‚åº¦çš„å‚æ•°ï¼Œä¾‹å¦‚`max_depth`ã€‚å¦‚æœç®—åŠ›å……è¶³ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åŠ å…¥`criterion`è¿™æ ·æˆ–è®¸ä¼šæœ‰æ•ˆçš„å‚æ•°

åœ¨æ­¤ä¾‹ä¸­ï¼Œå…·ä½“æ¯ä¸ªå‚æ•°çš„åˆå§‹èŒƒå›´ç¡®å®šå¦‚ä¸‹ï¼š

|          å‚æ•°           |                             èŒƒå›´                             |
| :---------------------: | :----------------------------------------------------------: |
|         `loss`          | å›å½’æŸå¤±ä¸­4ç§å¯é€‰æŸå¤±å‡½æ•°<br>["squared_error","absolute_error", "huber", "quantile"] |
|       `criterion`       | å…¨éƒ¨å¯é€‰çš„4ç§ä¸çº¯åº¦è¯„ä¼°æŒ‡æ ‡<br>["friedman_mse", "squared_error", "mse", "mae"] |
|         `init`          |  HyperOptä¸æ”¯æŒæœç´¢ï¼Œæ‰‹åŠ¨è°ƒå‚ï¼ˆæ­¤åˆ—ä¸­æŒ‰ç…§`init`=rfæ¥åˆå§‹ï¼‰   |
|     `n_estimators`      |      ç»ç”±æå‰åœæ­¢ç¡®è®¤ä¸­é—´æ•°50ï¼Œæœ€åèŒƒå›´å®šä¸º(25,200,25)       |
|     `learning_rate`     | ä»¥1.0ä¸ºä¸­å¿ƒå‘ä¸¤è¾¹å»¶å±•ï¼Œæœ€åèŒƒå›´å®šä¸º(0.05,2.05,0.05)<br>*å¦‚æœç®—åŠ›æœ‰é™ï¼Œä¹Ÿå¯å®šä¸º(0.1,2.1,0.1) |
|     `max_features`      |              æ‰€æœ‰å­—ç¬¦ä¸²ï¼Œå¤–åŠ sqrtä¸autoä¸­é—´çš„å€¼              |
|       `subsample`       | subsampleå‚æ•°çš„å–å€¼èŒƒå›´ä¸º(0,1]ï¼Œå› æ­¤å®šèŒƒå›´(0.1,0.8,0.1)<br>*å¦‚æœç®—åŠ›æœ‰é™ï¼Œä¹Ÿå¯å®šä¸º(0.5,0.8,0.1) |
|       `max_depth`       |   ä»¥3ä¸ºä¸­å¿ƒå‘ä¸¤è¾¹å»¶å±•ï¼Œå³ä¾§èŒƒå›´å®šå¾—æ›´å¤§ã€‚æœ€åç¡®è®¤(2,30,2)    |
| `min_impurity_decrease` |   åªèƒ½æ”¾å¤§ï¼ˆé»˜è®¤å€¼ä¸º0ï¼‰ã€ä¸èƒ½ç¼©å°çš„å‚æ•°ï¼Œå…ˆå°è¯•(0,5,1)èŒƒå›´   |

## GradientBoostingRegreesorå®ç°-é»˜è®¤å‚æ•°

```python
# å¯¼å…¥ç›¸å…³åº“
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingRegressor as GBR
from sklearn.ensemble import GradientBoostingClassifier as GBC
from sklearn.ensemble import AdaBoostRegressor as ABR
from sklearn.ensemble import RandomForestRegressor as RFR
from sklearn.model_selection import cross_validate, KFold
```

```python
# è¯»å–train_encodeæ–‡ä»¶
data = pd.read_csv(r"D:\Pythonwork\2021ML\PART 2 Ensembles\datasets\House Price\train_encode.csv",index_col=0)

# å®šä¹‰ç‰¹å¾æ•°æ®é›†å’Œæ ‡ç­¾æ•°æ®é›†
X = data.iloc[:,:-1]
y = data.iloc[:,-1]

# å®šä¹‰æ‰€éœ€çš„5æŠ˜äº¤å‰éªŒè¯æ–¹å¼ï¼šéšæœºæ•°ä¸º1412å’Œå°è£…å‡½æ•°RMSEæŸ¥çœ‹
cv = KFold(n_splits=5,shuffle=True,random_state=1412)

def RMSE(result,name):
    return abs(result[name].mean())
```

```python
# å®ä¾‹åŒ–é»˜è®¤å‚æ•°çš„GBRæ¨¡å‹
gbr = GBR(random_state=1412) #å®ä¾‹åŒ–

# å¯¹å…¶è¿›è¡Œäº¤å‰éªŒè¯
result_gbdt = cross_validate(gbr,X,y,
                             cv=cv,
                             scoring="neg_root_mean_squared_error",#è´Ÿå‡æ–¹æ ¹è¯¯å·®
                             return_train_score=True,
                             verbose=True, 
                             n_jobs=-1)

# æŸ¥çœ‹è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šçš„RMSE
RMSE(result_gbdt,"train_score")ï¼Œ RMSE(result_gbdt,"test_score")
```



## GradientBoostingClassifierå®ç°--é»˜è®¤å‚æ•°

```python
#åˆ†ç±»æ•°æ®
X_clf = data.iloc[:,:-2]
y_clf = data.iloc[:,-2]
```

```python
# GBDTåˆ†ç±»è¿‡ç¨‹çš„å®ç°ï¼ˆcodeï¼‰
clf = GBC(random_state=1412) #å®ä¾‹åŒ–
cv = KFold(n_splits=5,shuffle=True,random_state=1412)
result_clf = cross_validate(clf,X_clf,y_clf,cv=cv
                            ,return_train_score=True
                            ,verbose=True
                            ,n_jobs=-1)
```

```python
# æŸ¥çœ‹æ¨¡å‹åœ¨æµ‹è¯•é›†å’Œè®­ç»ƒé›†ä¸Šçš„è¡¨ç°
result_clf["train_score"].mean(), result_clf["test_score"].mean()
```

## åŸºäºTPEå¯¹GBDTè¿›è¡Œä¼˜åŒ–

```python
# å¯¼å…¥åŸºæœ¬åº“å’Œsklearnç›¸å…³åº“
import pandas as pd
import numpy as np
import sklearn
import matplotlib as mlp
import matplotlib.pyplot as plt
import time
from sklearn.ensemble import RandomForestRegressor as RFR
from sklearn.ensemble import GradientBoostingRegressor as GBR
from sklearn.model_selection import cross_validate, KFold

#  å¯¼å…¥ä¼˜åŒ–ç®—æ³•ç›¸å…³åº“
import hyperopt
from hyperopt import hp, fmin, tpe, Trials, partial
from hyperopt.early_stop import no_progress_loss
```

```python
# è¯»å–æ•°æ®
data = pd.read_csv(r"train_encode.csv",index_col=0)

# è®¾ç½®ç‰¹å¾æ•°æ®é›†å’Œç‰¹å¾æ•°æ®é›†
X = data.iloc[:,:-1]
y = data.iloc[:,-1]
```

1. ### å»ºç«‹benchmark

|        ç®—æ³•         |    RF     | AdaBoost  |   GBDT    | RF<br>(TPE) | AdaBoost<br>(TPE) |
| :-----------------: | :-------: | :-------: | :-------: | :---------: | :---------------: |
| 5æŠ˜éªŒè¯<br>è¿è¡Œæ—¶é—´ |   1.29s   |   0.28s   |   0.49s   |    0.22s    |       0.27s       |
| æœ€ä¼˜åˆ†æ•°<br>(RMSE)  | 30571.267 | 35345.931 | 28783.954 |  28346.673  |     35169.730     |

2. ### å®šä¹‰å‚æ•°`init`éœ€è¦çš„ç®—æ³•

```python
rf = RFR(n_estimators=89, max_depth=22, max_features=14,min_impurity_decrease=0
         ,random_state=1412, verbose=False, n_jobs=-1)
```

3. å®šä¹‰ç›®æ ‡å‡½æ•°ã€å‚æ•°ç©ºé—´ã€ä¼˜åŒ–å‡½æ•°ã€éªŒè¯å‡½æ•°

   1. ç›®æ ‡å‡½æ•°

      ```python
      def hyperopt_objective(params):
          reg = GBR(n_estimators = int(params["n_estimators"])
                    ,learning_rate = params["lr"]
                    ,criterion = params["criterion"]
                    ,loss = params["loss"]
                    ,max_depth = int(params["max_depth"])
                    ,max_features = params["max_features"]
                    ,subsample = params["subsample"]
                    ,min_impurity_decrease = params["min_impurity_decrease"]
                    ,init = rf
                    ,random_state=1412
                    ,verbose=False)
          
          cv = KFold(n_splits=5,shuffle=True,random_state=1412)
          validation_loss = cross_validate(reg,X,y
                                           ,scoring="neg_root_mean_squared_error"
                                           ,cv=cv
                                           ,verbose=False
                                           ,n_jobs=-1
                                           ,error_score='raise'
                                          )
          return np.mean(abs(validation_loss["test_score"]))
      ```

   2. å‚æ•°ç©ºé—´

      |          å‚æ•°           |                             èŒƒå›´                             |
      | :---------------------: | :----------------------------------------------------------: |
      |         `loss`          | å›å½’æŸå¤±ä¸­4ç§å¯é€‰æŸå¤±å‡½æ•°<br>["squared_error","absolute_error", "huber", "quantile"] |
      |       `criterion`       | å…¨éƒ¨å¯é€‰çš„4ç§ä¸çº¯åº¦è¯„ä¼°æŒ‡æ ‡<br>["friedman_mse", "squared_error", "mse", "mae"] |
      |         `init`          |                 HyperOptä¸æ”¯æŒæœç´¢ï¼Œæ‰‹åŠ¨è°ƒå‚                 |
      |     `n_estimators`      |      ç»ç”±æå‰åœæ­¢ç¡®è®¤ä¸­é—´æ•°50ï¼Œæœ€åèŒƒå›´å®šä¸º(25,200,25)       |
      |     `learning_rate`     | ä»¥1.0ä¸ºä¸­å¿ƒå‘ä¸¤è¾¹å»¶å±•ï¼Œæœ€åèŒƒå›´å®šä¸º(0.05,2.05,0.05)<br>*å¦‚æœç®—åŠ›æœ‰é™ï¼Œä¹Ÿå¯å®šä¸º(0.1,2.1,0.1) |
      |     `max_features`      |              æ‰€æœ‰å­—ç¬¦ä¸²ï¼Œå¤–åŠ sqrtä¸autoä¸­é—´çš„å€¼              |
      |       `subsample`       | subsampleå‚æ•°çš„å–å€¼èŒƒå›´ä¸º(0,1]ï¼Œå› æ­¤å®šèŒƒå›´(0.1,0.8,0.1)<br>*å¦‚æœç®—åŠ›æœ‰é™ï¼Œä¹Ÿå¯å®šä¸º(0.5,0.8,0.1) |
      |       `max_depth`       |   ä»¥3ä¸ºä¸­å¿ƒå‘ä¸¤è¾¹å»¶å±•ï¼Œå³ä¾§èŒƒå›´å®šå¾—æ›´å¤§ã€‚æœ€åç¡®è®¤(2,30,2)    |
      | `min_impurity_decrease` |         åªèƒ½æ”¾å¤§ã€ä¸èƒ½ç¼©å°çš„å‚æ•°ï¼Œå…ˆå°è¯•(0,5,1)èŒƒå›´          |

      ```python
      param_grid_simple = {'n_estimators': hp.quniform("n_estimators",25,200,25)
                        ,"lr": hp.quniform("learning_rate",0.05,2.05,0.05)
                        ,"criterion": hp.choice("criterion",["friedman_mse", "squared_error"])
                        ,"loss":hp.choice("loss",["squared_error","absolute_error", "huber", "quantile"])
                        ,"max_depth": hp.quniform("max_depth",2,30,2)
                        ,"subsample": hp.quniform("subsample",0.1,0.8,0.1)
                        ,"max_features": hp.choice("max_features",["log2","sqrt",16,32,64])
                        ,"min_impurity_decrease":hp.quniform("min_impurity_decrease",0,5,1)
                       }
      ```

   3. ä¼˜åŒ–å‡½æ•°

      ```python
      def param_hyperopt(max_evals=100):
          
          #ä¿å­˜è¿­ä»£è¿‡ç¨‹
          trials = Trials()
          
          #è®¾ç½®æå‰åœæ­¢
          early_stop_fn = no_progress_loss(100)
          
          #å®šä¹‰ä»£ç†æ¨¡å‹
          params_best = fmin(hyperopt_objective
                             , space = param_grid_simple
                             , algo = tpe.suggest	# TPEå…·æœ‰å¼ºéšæœºæ€§
                             , max_evals = max_evals
                             , verbose=True
                             , trials = trials
                             , early_stop_fn = early_stop_fn
                            )
          
          #æ‰“å°æœ€ä¼˜å‚æ•°ï¼Œfminä¼šè‡ªåŠ¨æ‰“å°æœ€ä½³åˆ†æ•°
          print("\n","\n","best params: ", params_best,
                "\n")
          return params_best, trials
      ```

   4. éªŒè¯å‡½æ•°ï¼ˆå¯é€‰ï¼‰

      ```python
      def hyperopt_validation(params):    
          reg = GBR(n_estimators = int(params["n_estimators"])
                    ,learning_rate = params["learning_rate"]
                    ,criterion = params["criterion"]
                    ,loss = params["loss"]
                    ,max_depth = int(params["max_depth"])
                    ,max_features = params["max_features"]
                    ,subsample = params["subsample"]
                    ,min_impurity_decrease = params["min_impurity_decrease"]
                    ,init = rf
                    ,random_state=1412 #GBRä¸­çš„random_stateåªèƒ½å¤Ÿæ§åˆ¶ç‰¹å¾æŠ½æ ·ï¼Œä¸èƒ½æ§åˆ¶æ ·æœ¬æŠ½æ ·
                    ,verbose=False)
          cv = KFold(n_splits=5,shuffle=True,random_state=1412)
          validation_loss = cross_validate(reg,X,y
                                           ,scoring="neg_root_mean_squared_error"
                                           ,cv=cv
                                           ,verbose=False
                                           ,n_jobs=-1
                                          )
          return np.mean(abs(validation_loss["test_score"]))
      ```

4. è®­ç»ƒè´å¶æ–¯ä¼˜åŒ–å™¨

   ```python
   # ä»¥æœ€å¤§æ¬¡æ•°ä¸º30è®­ç»ƒè´å¶æ–¯ä¼˜åŒ–å™¨
   params_best, trials = param_hyperopt(30)
   ```

   

